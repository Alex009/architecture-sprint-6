# Задача

Проанализируйте текущую архитектуру. Создайте текстовый документ и напишите там список проблем и рисков, которые связаны
с планируемым ростом нагрузки.

# Решение

## Проблемы и риски

Сервис `ins-product-aggregator` работает в синхронном режиме, а значит:

1. чем больше источников информации у нас будет - тем дольше будет выполняться запрос (а планируется рост с 5 до 10
   источников).
2. при возникновении ошибки связи с внешней системой мы получим ошибку и для системы, вызвавшей запрос (ведь нам нужны
   данные здесь и сейчас).

Сервис `ins-comp-settlement` раз в сутки запрашивает у `core-app` весь список оформленных страховок за день, а значит:

1. мы получаем повышенную нагрузку в раз в сутки, так как выкачиваем большой набор данных. Это может влиять на
   производительность сервиса для пользователей в этот момент.
2. у нас есть задержка между моментом оформления страховки и фиксацией этой информации в страховой компании (внешней
   системе).

Также у сервисов `ins-comp-settlement` и `core-app` временная рассинхронизация данных - `core-app` каждые 15 минут
получает более новую версию продуктов и тарифов, а `ins-comp-settlement` только раз в день. Есть вероятность, что эта
разница может привести к ошибке оформления страховки.

Главный риск при росте нагрузки - увеличение количества ошибок при попытке получения данных о продуктах и тарифах.

## План исправления

Вместо периодического запроса от `core-app` к `ins-product-aggregator` нужно сделать передачу событий и регулярную
задачу получения данных.

`ins-product-aggregator` по расписанию (например через каждые 15 минут брать с каждой внешней системы её данные,
параллельно) должен получать данные от внешних систем и через шину событий сообщать что есть новые данные, которые
`core-app`, а также `ins-comp-settlement` получат и сохранят в своей бд.

В случае если какая-то из внешних систем выдала ошибку - мы автоматически пробуем повторить (если ошибка выглядит
временной). Таким образом ошибки работы с внешними сервисами никак не повлияют на скорость работы нашей системы, может
быть только отставание в данных больше чем 15 минут от внешней системы. Ошибки точно должны отправляться в мониторинг и
алертиться, но возможно при значительном устаревании закешированных данных нужно чтобы `core-app` выводил устаревшие
продукты из доступных для юзеров - например если устаревание в 6 часов (тут стоит с самими страховыми компаниями
обсуждать насколько нормально будет если произойдет случай оформления страховки по цене, которая уже 5 часов как не
актуально согласно данным самой страховой).

Для передачи событий из `ins-product-aggregator` в `core-app` / `ins-comp-settlement` нам не так уж важно потеряется ли
конкретное событие из-за разового сбоя (через небольшое время - 15 минут, данные повторно отправятся всё равно). Поэтому
Transactional Outbox тут применять нет смысла, также как и добавлять свою базу данных для хранения чего либо.

Например, берем Kafka, и `ins-product-aggregator` отправляет в неё события, а `core-app`, `ins-comp-settlement`
подписываются на топик обновления данных по продуктам и тарифам.

Также, для оптимизации работы взаиморасчетов, добавим передачу событий от `core-app` в `ins-comp-settlement` (точнее
`core-app` просто будет сообщать о событии оформления новой страховки).
В данном случае нам важно чтобы данные были точно отправлены. Поэтому нужно применить Transactional Outbox, то есть
сохранять запись для отправки в очередь в той же транзакции, которая пишет запись про оформленную страховку. А другая
логика в `core-app` по расписанию (каждую минуту например) смотрит в Transactional Outbox, отправляет в очередь события,
и в случае успеха - удаляет из Outbox (чтобы не раздувать размер бд зазря).
